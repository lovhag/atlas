{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Atlas answer generation for ParaRel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2021-23-309/envs/atlas_venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load T5 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/t5-base-lm-adapt\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/t5-base-lm-adapt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 32128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<extra_id_0>',\n",
       " 'cute',\n",
       " 'dog',\n",
       " '',\n",
       " '<extra_id_1>',\n",
       " 'the',\n",
       " '',\n",
       " '<extra_id_2>',\n",
       " '</s>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(val) for val in labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 32128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'park', 'little', 'park', 'walker', '.', '', 's', '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(logit.argmax()) for logit in logits[0,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small options test with logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(8.5687),\n",
       " tensor(11.2431),\n",
       " tensor(11.9538),\n",
       " tensor(11.9589),\n",
       " tensor(9.8689),\n",
       " tensor(11.2803),\n",
       " tensor(9.4624),\n",
       " tensor(11.6552),\n",
       " tensor(13.3678)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"The Eiffel Tower is located in <extra_id_0>.\"\n",
    "options = [\"Paris\",\"China\",\"Sweden\",\"Greece\",\"Shoe\",\"Canada\",\"France\",\"here\",\"horse\"]\n",
    "\n",
    "input_ids = tokenizer(query, return_tensors=\"pt\").input_ids\n",
    "\n",
    "option_losses = []\n",
    "for option in options:\n",
    "    tmp_label = tokenizer(f\"<extra_id_0> {option}\", return_tensors=\"pt\").input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, labels=tmp_label)\n",
    "    option_losses.append(outputs.loss)\n",
    "    \n",
    "option_losses    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ParaRel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = \"/cephyr/users/lovhag/Alvis/projects/pararel/data/all_n1_atlas_no_space/P138_100.jsonl\"\n",
    "options_file = \"/cephyr/users/lovhag/Alvis/projects/pararel/data/all_n1_atlas_no_space/P138_100_options.txt\"\n",
    "\n",
    "queries = []\n",
    "with open(query_file) as f:\n",
    "    for line in f.readlines():\n",
    "        queries.append(json.loads(line))\n",
    "\n",
    "options = []\n",
    "with open(options_file) as f:\n",
    "    for line in f.readlines():\n",
    "        options.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'aristotelianism, named for<extra_id_0>.',\n",
       " 'sub_label': 'aristotelianism',\n",
       " 'answers': ['Aristotle'],\n",
       " 'pattern': '[X], named for [Y].'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with adding sentinel id on token level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Atlas code, the masked language modelling is done as follows:\n",
    "\n",
    "```python\n",
    "    sentinel_id = tokenizer.additional_special_tokens_ids[i]\n",
    "    inputs += tokens[offset : offset + inp_length] + [sentinel_id]\n",
    "    offset += inp_length\n",
    "    outputs += [sentinel_id] + tokens[offset : offset + out_length]\n",
    "    offset += out_length\n",
    "\n",
    "tokenizer.decode(inputs), tokenizer.decode(outputs)            \n",
    "```\n",
    "\n",
    "Meaning that the text is first tokenized, and then the masking is applied. So masking is done on the input ids level. Potentially, this means that the surrounding token ids look differently, compared to if the masking is done on text level. We will here investigate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlm_approach_input(question_with_sentinel_id, answer_option):\n",
    "    sentinel_id = tokenizer.additional_special_tokens_ids[0]\n",
    "    full_example = question_with_sentinel_id.replace(\"<extra_id_0>\", \" \"+answer_option) #need to add our own space\n",
    "    full_example_ids = tokenizer(full_example)[\"input_ids\"]\n",
    "    answer_ids = tokenizer(answer_option, add_special_tokens=False)[\"input_ids\"]\n",
    "    answer_ix = None\n",
    "    # find where ids match the answer ids\n",
    "    for i in range(len(full_example_ids)-len(answer_ids)):\n",
    "        if full_example_ids[i:i+len(answer_ids)]==answer_ids:\n",
    "            answer_ix = i\n",
    "            break\n",
    "    if answer_ix is None:\n",
    "        raise ValueError(f\"found no matching answer index in '{full_example_ids}' for '{answer_ids}'\")\n",
    "    question_tokens = full_example_ids[:answer_ix]+[sentinel_id]+full_example_ids[answer_ix+len(answer_ids):]\n",
    "    answer_tokens = [sentinel_id] + answer_ids\n",
    "    return tokenizer.decode(question_tokens), tokenizer.decode(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles is named after Paul.</s>\n",
      "Text level: Pauline epistles is named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles was named after Paul.</s>\n",
      "Text level: Pauline epistles was named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles is named for Paul.</s>\n",
      "Text level: Pauline epistles is named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles was named for Paul.</s>\n",
      "Text level: Pauline epistles was named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which is named after Paul.</s>\n",
      "Text level: Pauline epistles, which is named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which was named after Paul.</s>\n",
      "Text level: Pauline epistles, which was named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which is named for Paul.</s>\n",
      "Text level: Pauline epistles, which is named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which was named for Paul.</s>\n",
      "Text level: Pauline epistles, which was named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, named for Paul.</s>\n",
      "Text level: Pauline epistles, named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, named after Paul.</s>\n",
      "Text level: Pauline epistles, named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles is named in Paul's honor.</s>\n",
      "Text level: Pauline epistles is named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles was named in Paul's honor.</s>\n",
      "Text level: Pauline epistles was named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, named in Paul's honor.</s>\n",
      "Text level: Pauline epistles, named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which is named in Paul's honor.</s>\n",
      "Text level: Pauline epistles, which is named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which was named in Paul's honor.</s>\n",
      "Text level: Pauline epistles, which was named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles is called after Paul.</s>\n",
      "Text level: Pauline epistles is called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles was called after Paul.</s>\n",
      "Text level: Pauline epistles was called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which is called after Paul.</s>\n",
      "Text level: Pauline epistles, which is called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, which was called after Paul.</s>\n",
      "Text level: Pauline epistles, which was called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0>ine epistles, called after Paul.</s>\n",
      "Text level: Pauline epistles, called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island is named after Christmas.</s>\n",
      "Text level: Christmas Island is named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island was named after Christmas.</s>\n",
      "Text level: Christmas Island was named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island is named for Christmas.</s>\n",
      "Text level: Christmas Island is named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island was named for Christmas.</s>\n",
      "Text level: Christmas Island was named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which is named after Christmas.</s>\n",
      "Text level: Christmas Island, which is named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which was named after Christmas.</s>\n",
      "Text level: Christmas Island, which was named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which is named for Christmas.</s>\n",
      "Text level: Christmas Island, which is named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which was named for Christmas.</s>\n",
      "Text level: Christmas Island, which was named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, named for Christmas.</s>\n",
      "Text level: Christmas Island, named for<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, named after Christmas.</s>\n",
      "Text level: Christmas Island, named after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island is named in Christmas's honor.</s>\n",
      "Text level: Christmas Island is named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island was named in Christmas's honor.</s>\n",
      "Text level: Christmas Island was named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, named in Christmas's honor.</s>\n",
      "Text level: Christmas Island, named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which is named in Christmas's honor.</s>\n",
      "Text level: Christmas Island, which is named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which was named in Christmas's honor.</s>\n",
      "Text level: Christmas Island, which was named in<extra_id_0>'s honor.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island is called after Christmas.</s>\n",
      "Text level: Christmas Island is called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island was called after Christmas.</s>\n",
      "Text level: Christmas Island was called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which is called after Christmas.</s>\n",
      "Text level: Christmas Island, which is called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, which was called after Christmas.</s>\n",
      "Text level: Christmas Island, which was called after<extra_id_0>.</s>\n",
      "Mismatched token vs. text level input found.\n",
      "Token level: <extra_id_0> Island, called after Christmas.</s>\n",
      "Text level: Christmas Island, called after<extra_id_0>.</s>\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    for option in options:\n",
    "        token_level_input, token_level_output = get_mlm_approach_input(query['question'], option)\n",
    "        text_level_input = tokenizer.decode(tokenizer(query['question'])[\"input_ids\"])\n",
    "        text_level_output = f\"<extra_id_0> {option}\"\n",
    "        if not token_level_input == text_level_input:\n",
    "            print(\"Mismatched token vs. text level input found.\")\n",
    "            print(f\"Token level: {token_level_input}\")\n",
    "            print(f\"Text level: {text_level_input}\")\n",
    "        if not token_level_output == text_level_output:\n",
    "            print(\"Mismatched token vs. text level output found.\")\n",
    "            print(f\"Token level: {token_level_output}\")\n",
    "            print(f\"Text level: {text_level_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baron de Hirsch Cemetery, Halifax, which is located in<extra_id_0>.</s>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_level_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<extra_id_0> Yemen'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_level_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kings Domain, located inFiji.</s>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([13913, 13979, 6, 1069, 16, 371, 17279, 5, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
